from fastapi import FastAPI
from pydantic import BaseModel
import pandas as pd
import numpy as np



import pickle
import os
from pathlib import Path

app = FastAPI()

# --------- CHARGEMENT DU MOD√àLE ET DU PREPROCESSEUR ----------
MODEL_DIR = Path("models")

# Charger le mod√®le entra√Æn√©
try:
    with open(MODEL_DIR / "best_model.pkl", "rb") as f:
        model = pickle.load(f)
    
    with open(MODEL_DIR / "preprocessor.pkl", "rb") as f:
        preprocessor = pickle.load(f)
    
    with open(MODEL_DIR / "model_metadata.pkl", "rb") as f:
        metadata = pickle.load(f)
    
    print(f"‚úÖ Mod√®le charg√©: {metadata['model_name']}")
    print(f"‚úÖ Performance: {metadata['test_score']:.4f} R¬≤")
    print(f"‚úÖ Features: {len(metadata['features'])} variables")
    
except FileNotFoundError as e:
    print(f"‚ùå Erreur: Fichier mod√®le non trouv√©: {e}")
    model = None
    preprocessor = None
    metadata = None

# --------- INPUT SCHEMA (match Streamlit payload) ----------
class InputData(BaseModel):
    sq_mt_built: float
    n_rooms: int
    n_bathrooms: float
    neighborhood: int
    product: str  # Type de bien (appartement, maison, etc.)

    has_lift: int = 0
    has_parking: int = 0
    has_pool: int = 0
    has_garden: int = 0
    has_storage_room: int = 0
    is_floor_under: int = 0


@app.get("/")
def read_root():
    return {
        "message": "API d'estimation immobili√®re avec StandardScaler",
        "model": metadata["model_name"] if metadata else "Non charg√©",
        "performance": f"{metadata['test_score']:.4f} R¬≤" if metadata else "N/A",
        "features": len(metadata['features']) if metadata else 0
    }


def preprocess_input(payload: InputData) -> pd.DataFrame:
    """Convertit les donn√©es d'entr√©e en DataFrame avec les bonnes colonnes et le bon ordre"""
    
    # Cr√©er un DataFrame avec l'ordre EXACT du notebook 
    # (d'apr√®s vos m√©tadonn√©es : numeric_features + categorical_features)
    data_dict = {
        # Ordre des features num√©riques (comme dans le notebook)
        'sq_mt_built': [payload.sq_mt_built],
        'n_rooms': [payload.n_rooms],
        'n_bathrooms': [payload.n_bathrooms],
        'has_lift': [payload.has_lift],
        'has_parking': [payload.has_parking],
        'has_pool': [payload.has_pool],
        'has_garden': [payload.has_garden],
        'has_storage_room': [payload.has_storage_room],
        'is_floor_under': [payload.is_floor_under],
        # Feature cat√©gorielle en dernier
        'neighborhood': [payload.neighborhood]
    }
    
    df = pd.DataFrame(data_dict)
    
    # R√©organiser selon l'ordre exact des m√©tadonn√©es du mod√®le
    if metadata and 'features' in metadata:
        # Utiliser l'ordre exact sauvegard√© lors de l'entra√Ænement
        df = df[metadata['features']]
        print(f"‚úÖ Colonnes r√©organis√©es selon m√©tadonn√©es: {list(df.columns)}")
    
    # Forcer neighborhood en cat√©gorie (comme dans le notebook)
    df["neighborhood"] = df["neighborhood"].astype("category")
    
    print(f"‚úÖ DataFrame final: colonnes = {list(df.columns)}")
    print(f"‚úÖ Types: {dict(df.dtypes)}")
    
    return df


@app.post("/predict")
def predict(data: InputData):
    """Pr√©diction de prix avec le mod√®le entra√Æn√©"""
    
    if model is None or preprocessor is None:
        return {"error": "Mod√®le non charg√©. V√©rifiez les fichiers dans /models/"}
    
    try:
        print(f"üì• Requ√™te re√ßue: {data}")
        
        # 1. Preprocessing des donn√©es d'entr√©e
        df_input = preprocess_input(data)
        print(f"‚úÖ DataFrame cr√©√©: {df_input}")
        print(f"‚úÖ Shape: {df_input.shape}")
        print(f"‚úÖ Colonnes: {list(df_input.columns)}")
        
        # 2. Appliquer le m√™me preprocesseur que dans le notebook
        X_scaled = preprocessor.transform(df_input)
        print(f"‚úÖ Transformation appliqu√©e: {X_scaled.shape}")
        
        # 3. Pr√©diction selon le mod√®le utilis√©
        if metadata["model_name"] == "Linear Regression":
            # Linear Regression utilise les donn√©es scal√©es (comme dans le notebook)
            log_price_pred = model.predict(X_scaled)[0]
            print(f"‚úÖ Pr√©diction LR (donn√©es scal√©es): {log_price_pred}")
        else:
            # Random Forest utilise les donn√©es BRUTES avec l'ordre exact du training
            # df_input a d√©j√† l'ordre correct gr√¢ce √† preprocess_input()
            log_price_pred = model.predict(df_input)[0]
            print(f"‚úÖ Pr√©diction RF (donn√©es brutes): {log_price_pred}")
            print(f"‚úÖ Features utilis√©es: {list(df_input.columns)}")
        
        # 4. Conversion log -> prix r√©el
        price_pred = np.exp(log_price_pred)
        print(f"‚úÖ Prix final: {price_pred}")
        
        result = {
            "prediction": int(price_pred),
            "log_prediction": float(log_price_pred),
            "model_used": metadata["model_name"],
            "preprocessing_applied": True,
            "features_count": X_scaled.shape[1],
            "input_data": data.dict(),
            "r2_score": metadata["test_score"]
        }
        
        print(f"üì§ R√©ponse envoy√©e: {result}")
        return result

    except Exception as e:
        error_msg = f"Erreur lors de la pr√©diction: {str(e)}"
        print(f"‚ùå {error_msg}")
        import traceback
        traceback.print_exc()
        return {"error": error_msg}


@app.get("/model-info")
def model_info():
    """Informations d√©taill√©es sur le mod√®le"""
    if metadata is None:
        return {"error": "Mod√®le non charg√©"}
    
    return {
        "model_name": metadata["model_name"],
        "performance_r2": metadata["test_score"],
        "total_features": len(metadata["features"]),
        "numeric_features": metadata["numeric_features"],
        "categorical_features": metadata["categorical_features"],
        "features_list": metadata["features"]
    }