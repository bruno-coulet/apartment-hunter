# M√©thodologie Scientifique

## **Probl√©matique**

**Objectif** : D√©velopper un syst√®me de pr√©diction de prix immobilier adaptatif capable d'optimiser ses performances selon la taille du dataset disponible.

**Hypoth√®se** : Une approche ML adaptative (feature selection et hyperparameter tuning conditionnels) am√©liore les performances sur des datasets de tailles diff√©rentes en √©vitant l'overfitting sur les petits datasets.

## **Approche Innovante : ML Adaptatif**

### Principe Fondamental

Notre m√©thodologie s'appuie sur un principe cl√© en Machine Learning : **la complexit√© du mod√®le doit √™tre proportionnelle √† la taille du dataset**.

```
Dataset Grande Taille ‚Üí Mod√®le Complexe + Optimisations
Dataset Petite Taille ‚Üí Mod√®le Simple + R√©gularisation
```

### Seuils de D√©cision

| Taille Dataset | Strat√©gie | Justification |
|-----------------|-----------|---------------|
| **> 15,000** | Feature Selection + Grid Search | Robuste aux optimisations |
| **< 5,000** | Mod√®le par d√©faut | √âvite l'overfitting |

## **Datasets Analys√©s**

### Appartements
- **Taille** : 19,125 √©chantillons
- **Statut** : Dataset "large" 
- **Strat√©gie** : Optimisation compl√®te
- **Justification** : Suffisamment de donn√©es pour supporter feature selection et grid search

### Maisons  
- **Taille** : 2,617 √©chantillons
- **Statut** : Dataset "petit"
- **Strat√©gie** : Mod√®le simple
- **Justification** : Risque √©lev√© d'overfitting avec optimisations

## üß™ **Plan Exp√©rimental**

### Phase 1 : Baseline
1. **Train/Test Split** : 80/20 stratifi√©
2. **Algorithmes test√©s** : RandomForest, Ridge, GradientBoosting
3. **Configuration** : Param√®tres par d√©faut
4. **M√©trique** : R¬≤ (coefficient de d√©termination)

### Phase 2 : Feature Selection (Appartements uniquement)
1. **M√©thode** : SelectKBest avec F-regression
2. **R√©duction** : 6 ‚Üí 5 features (17% r√©duction)
3. **Validation** : Importance des scores F

### Phase 3 : Grid Search (Appartements uniquement)  
1. **Validation crois√©e** : 5-fold CV
2. **M√©trique d'optimisation** : R¬≤
3. **Espace de recherche** : Param√®tres critiques par algorithme

### Phase 4 : Validation et Comparaison
1. **Test final** : Dataset de test non touch√©
2. **Comparaison** : Performance avant/apr√®s optimisation
3. **Analyse** : Justification des choix par dataset

## **M√©triques d'√âvaluation**

### Primaires
- **R¬≤ Score** : Variance expliqu√©e par le mod√®le
- **MAE** : Erreur absolue moyenne (interpr√©table en ‚Ç¨)

### Secondaires  
- **RMSE** : Erreur quadratique (p√©nalise les gros √©carts)
- **Temps d'entra√Ænement** : Performance computationnelle

### Crit√®res de Validation
- **G√©n√©ralisation** : R¬≤ test proche du R¬≤ train
- **Robustesse** : Performance stable en cross-validation
- **Interpr√©tabilit√©** : Features s√©lectionn√©es coh√©rentes m√©tier

## üîÑ **Processus de Validation**

### 1. Validation Crois√©e
```python
cv = KFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(model, X, y, cv=cv, scoring='r2')
```

### 2. Test de G√©n√©ralisation
```
R¬≤ Train vs R¬≤ Test
√âcart < 5% ‚Üí Bon mod√®le
√âcart > 10% ‚Üí Overfitting suspect√©
```

### 3. Validation des Features
```python
# Score F pour chaque feature
f_scores = selector.scores_
# Features les plus pr√©dictives conserv√©es
```

## **Hypoth√®ses Test√©es**

### H1 : Feature Selection am√©liore les performances sur grands datasets
**M√©thode** : Comparaison R¬≤ avant/apr√®s s√©lection (appartements)  
**R√©sultat** : - Valid√©e (75.32% ‚Üí 77.17%)

### H2 : Grid Search optimise significativement les hyperparam√®tres
**M√©thode** : Comparaison R¬≤ avant/apr√®s grid search (appartements)  
**R√©sultat** : - Valid√©e (77.17% ‚Üí 77.81%)

### H3 : √âviter l'optimisation sur petits datasets am√©liore la g√©n√©ralisation
**M√©thode** : Comparaison avec/sans optimisation (maisons)  
**R√©sultat** : - Valid√©e (59.93% avec ‚Üí 79.51% sans)

## **Analyse Statistique**

### Significance Tests
- **Test t** pour diff√©rences de performances
- **Confiance** : 95% 
- **Bootstrap** : 1000 √©chantillons pour intervalles de confiance

### Robustesse
- **Cross-validation** : Stabilit√© des performances  
- **Randomization** : Seed fix√© pour reproductibilit√©
- **Multiple runs** : Validation sur plusieurs executions

## **Gestion de l'Al√©atoire**

```python
# Reproductibilit√© garantie
random_state = 42  # Partout o√π applicable
np.random.seed(42)
```

## **Limitations et Biais**

### Limitations Identifi√©es
1. **Temporalit√©** : Pas de features temporelles
2. **G√©olocalisation** : Quartiers vs coordonn√©es pr√©cises  
3. **Features externes** : Pas d'infos march√©/√©conomiques

### Biais Potentiels
1. **Biais de s√©lection** : Donn√©es uniquement Madrid
2. **Biais temporel** : P√©riode sp√©cifique de collecte
3. **Biais algorithmique** : Favorise certains types de propri√©t√©s

### Mitigation
1. **Validation robuste** : Multiple CV folds
2. **M√©triques multiples** : R¬≤, MAE, RMSE  
3. **Analyse r√©sidus** : D√©tection patterns non captur√©s

---

## **Conclusion M√©thodologique**

L'approche adaptative par taille de dataset repr√©sente une innovation m√©thodologique qui d√©montre l'importance de **l'adaptation contextuelle** en Machine Learning plut√¥t que l'application syst√©matique d'optimisations complexes.

**R√©sultat cl√©** : +16% de performance sur les maisons en *√©vitant* la sur-optimisation.